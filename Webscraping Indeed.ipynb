{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, I will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "I am going to collect salary information on data science jobs in a variety of markets. Then using the location, title, and summary of the job I will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information, being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "I will convert this problem into classification and use a random forest classifier, as well as another classifier. \n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "I will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "The URL here has many query parameters\n",
    "- q for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- l for a location\n",
    "- start for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib import urlopen\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "html = urllib.urlopen(URL).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "len(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one result more closely. A single result looks like\n",
    "```JSON\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&campaignid=serp-linkcompanyname&fromjk=2480d203f7e97210&jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a nobr element inside of a td element with class='snip.\n",
    "- The title of a job is in a link with class set to jobtitle and a data-tn-element=\"jobTitle.\n",
    "- The location is set in a span with class='location'.\n",
    "- The company is set in a span with class='company'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to extract each item: location, company, job, and salary.¶\n",
    "Example\n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflocation = pd.DataFrame(columns=[\"location\"])\n",
    "dfcompany = pd.DataFrame(columns=[\"company\"])\n",
    "dfjob_title = pd.DataFrame(columns=[\"job_title\"])\n",
    "dfsalary = pd.DataFrame(columns=[\"salary\"])\n",
    "\n",
    "#result.find(‘a’,attrs={‘data-tn-element’:‘jobTitle’}).text\n",
    "def extract_location(result):\n",
    "    for b in result.find_all('span', {'class': 'location'}):\n",
    "        location = b.text\n",
    "        dflocation.loc[len(dflocation)] = [location]    \n",
    "        \n",
    "def extract_company(result):        \n",
    "    for i in result.find_all('span', {'class':'company'}):\n",
    "        company = i.text\n",
    "        dfcompany.loc[len(dfcompany)] = [company]   \n",
    "\n",
    "def extract_job_title(result):\n",
    "    for a in result.find_all('a', {'data-tn-element':'jobTitle'}):\n",
    "        job_title = a.text\n",
    "        dfjob_title.loc[len(dfjob_title)] = [job_title]\n",
    "\n",
    "def extract_salary(result):\n",
    "    for entry in result.find_all('td', {'class' : 'snip'}):\n",
    "        try:\n",
    "            salary = entry.find('nobr').text\n",
    "            dfsalary.loc[len(dfsalary)] = [salary]  \n",
    "        except:\n",
    "            salary = 'NA'\n",
    "            dfsalary.loc[len(dfsalary)] = [salary]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the l=New+York and the start=10. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making a list of cities to run through\n",
    "cities = ['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', 'washington+dc', 'boston', 'new+orleans', \n",
    "         'charlotte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>\\n\\n\\n    IBM\\n</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>\\n\\n    White Ops\\n</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York, NY 10017 (Midtown area)</td>\n",
       "      <td>\\n\\n\\n    Guidepoint\\n</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York, NY 10005 (Financial District area)</td>\n",
       "      <td>\\n\\n    Enterprise Select\\n</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>\\n\\n    Innovations for Poverty\\n</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       location  \\\n",
       "0                                  New York, NY   \n",
       "1                                  New York, NY   \n",
       "2             New York, NY 10017 (Midtown area)   \n",
       "3  New York, NY 10005 (Financial District area)   \n",
       "4                                  New York, NY   \n",
       "\n",
       "                             company       job_title salary  \n",
       "0                    \\n\\n\\n    IBM\\n  Data Scientist     NA  \n",
       "1                \\n\\n    White Ops\\n  Data Scientist     NA  \n",
       "2             \\n\\n\\n    Guidepoint\\n  Data Scientist     NA  \n",
       "3        \\n\\n    Enterprise Select\\n  Data Scientist     NA  \n",
       "4  \\n\\n    Innovations for Poverty\\n  Data Scientist     NA  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a dataframe which collects all the information from my webscraping\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 100 # Set this to a high-value to generate more results. \n",
    "\n",
    "df = pd.DataFrame(columns=[\"location\", 'company', 'job_title', 'salary'])\n",
    "\n",
    "for city in cities:\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        url = url_template.format(city,start)\n",
    "        html = urllib.urlopen(url).read()\n",
    "        soups = BeautifulSoup(html, \"html.parser\")\n",
    "        for b in soups.find_all('div', attrs = {'class':' row result'}):\n",
    "            location = b.find('span', attrs = {'class': 'location'}).text\n",
    "            job_title = b.find('a', attrs = {'data-tn-element':'jobTitle'}).text\n",
    "            try:\n",
    "                company = b.find('span', attrs = {'class':'company'}).text\n",
    "            except:\n",
    "                company = 'NA'\n",
    "            try:\n",
    "                salary = b.find('td', attrs = {'class' : 'snip'}).find('nobr').text  \n",
    "            except:\n",
    "                salary = 'NA'\n",
    "            df = df.append({\"location\":location,\"company\":company, \"job_title\": job_title, \"salary\": salary}, ignore_index=True) \n",
    "   \n",
    "df.head()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending it to csvs to save the data\n",
    "#df.to_csv(\"~/Desktop/April12.csv\" , sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "#reading in the data\n",
    "df1 = pd.read_csv('~/Desktop/GA/April10.csv')\n",
    "df2 = pd.read_csv('~/Desktop/GA/April11.csv')\n",
    "df3 = pd.read_csv('~/Desktop/GA/April12.csv')\n",
    "df4 = pd.read_csv('~/Desktop/GA/April1_11.csv')\n",
    "df5 = pd.read_csv('~/Desktop/GA/April2_11.csv')\n",
    "df6 = pd.read_csv('~/Desktop/GA/April_10.csv')\n",
    "df7 = pd.read_csv('~/Desktop/GA/April_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df1,df2,df3,df4,df5,df6,df7]) #making into one df\n",
    "data.drop(['Unnamed: 0'], axis=1, inplace=True) #resetting index\n",
    "data.drop_duplicates(inplace=True) #dropping duplicates\n",
    "data.company.replace(regex=True,inplace=True,to_replace=\"\\n\",value=\"\") #getting rid of /n in company\n",
    "data.salary.replace(regex=True, inplace=True, to_replace=\"\\$\", value=\"\") #getting rid of $ in salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values \n",
      "location        0\n",
      "company         3\n",
      "job_title       0\n",
      "salary       8134\n",
      "dtype: int64\n",
      "dataframe types \n",
      "location     object\n",
      "company      object\n",
      "job_title    object\n",
      "salary       object\n",
      "dtype: object\n",
      "dataframe shape \n",
      "(8698, 4)\n",
      "dataframe describe \n",
      "            location                 company       job_title          salary\n",
      "count           8698                    8695            8698             564\n",
      "unique           935                    3076            6498             334\n",
      "top     New York, NY          Ball Aerospace  Data Scientist  120,000 a year\n",
      "freq             653                     126             355              13\n",
      "dataframe length = 8698\n",
      "duplicates 0\n",
      "location\n",
      "935\n",
      "company\n",
      "3076\n",
      "job_title\n",
      "6498\n",
      "salary\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "def eda(dataframe): #code chunk to check quality of data\n",
    "    print \"missing values \\n\", dataframe.isnull().sum() #shows total amount of null values for each column\n",
    "    print \"dataframe types \\n\", dataframe.dtypes\n",
    "    print \"dataframe shape \\n\", dataframe.shape     \n",
    "    print \"dataframe describe \\n\", dataframe.describe()\n",
    "    print \"dataframe length =\", len(dataframe) #length of the dataframe\n",
    "    print \"duplicates\", dataframe.duplicated().sum() # added this to duplicates in the data\n",
    "    for item in dataframe:\n",
    "        print item\n",
    "        print dataframe[item].nunique()\n",
    "\n",
    "eda(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, I need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "I didn't think it was safe to multiply data for hour/week/month so I only wanted yearly data.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>402</td>\n",
       "      <td>401</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>122</td>\n",
       "      <td>197</td>\n",
       "      <td>317</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>120,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>59</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            location                     company       job_title  \\\n",
       "count            402                         401             402   \n",
       "unique           122                         197             317   \n",
       "top     New York, NY          Jobspring Partners  Data Scientist   \n",
       "freq              59                          25              26   \n",
       "\n",
       "                salary  \n",
       "count              402  \n",
       "unique             219  \n",
       "top     120,000 a year  \n",
       "freq                13  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries = data[data.salary.notnull()]\n",
    "salaries = salaries[salaries.salary.str.contains('year')] #only getting yearly salaries\n",
    "#http://stackoverflow.com/questions/15325182/how-to-filter-rows-in-pandas-by-regex\n",
    "salaries.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York, NY 10005 (Financial District area)</td>\n",
       "      <td>Barrington James</td>\n",
       "      <td>Real World Evidence Statistical Analyst</td>\n",
       "      <td>110000</td>\n",
       "      <td>[110000 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>PMES</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>155000</td>\n",
       "      <td>[155000 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>indify</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000 - 170000</td>\n",
       "      <td>[90000 ,  170000 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>WorldCover</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000 - 110000</td>\n",
       "      <td>[70000 ,  110000 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Envisagenics, Inc.</td>\n",
       "      <td>Data Architect/ Data Engineer</td>\n",
       "      <td>65000 - 110000</td>\n",
       "      <td>[65000 ,  110000 ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        location                   company  \\\n",
       "1   New York, NY 10005 (Financial District area)          Barrington James   \n",
       "5                                   New York, NY                      PMES   \n",
       "6                                   New York, NY                    indify   \n",
       "27                                  New York, NY                WorldCover   \n",
       "51                                  New York, NY        Envisagenics, Inc.   \n",
       "\n",
       "                                  job_title           salary  \\\n",
       "1   Real World Evidence Statistical Analyst          110000    \n",
       "5                         Sr Data Scientist          155000    \n",
       "6                            Data Scientist  90000 - 170000    \n",
       "27                           Data Scientist  70000 - 110000    \n",
       "51            Data Architect/ Data Engineer  65000 - 110000    \n",
       "\n",
       "          salary_split  \n",
       "1            [110000 ]  \n",
       "5            [155000 ]  \n",
       "6   [90000 ,  170000 ]  \n",
       "27  [70000 ,  110000 ]  \n",
       "51  [65000 ,  110000 ]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting my salaries to find an average\n",
    "salaries.salary.replace(regex=True, inplace=True, to_replace=\"a year\", value=\"\")\n",
    "salaries.salary.replace(regex=True, inplace=True, to_replace=\",\", value=\"\")\n",
    "salaries['salary_split'] = salaries['salary'].str.split('-')\n",
    "salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_split</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York, NY 10005 (Financial District area)</td>\n",
       "      <td>Barrington James</td>\n",
       "      <td>Real World Evidence Statistical Analyst</td>\n",
       "      <td>110000</td>\n",
       "      <td>[110000 ]</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>PMES</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>155000</td>\n",
       "      <td>[155000 ]</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>indify</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000 - 170000</td>\n",
       "      <td>[90000 ,  170000 ]</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>WorldCover</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000 - 110000</td>\n",
       "      <td>[70000 ,  110000 ]</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Envisagenics, Inc.</td>\n",
       "      <td>Data Architect/ Data Engineer</td>\n",
       "      <td>65000 - 110000</td>\n",
       "      <td>[65000 ,  110000 ]</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>87500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        location                   company  \\\n",
       "1   New York, NY 10005 (Financial District area)          Barrington James   \n",
       "5                                   New York, NY                      PMES   \n",
       "6                                   New York, NY                    indify   \n",
       "27                                  New York, NY                WorldCover   \n",
       "51                                  New York, NY        Envisagenics, Inc.   \n",
       "\n",
       "                                  job_title           salary  \\\n",
       "1   Real World Evidence Statistical Analyst          110000    \n",
       "5                         Sr Data Scientist          155000    \n",
       "6                            Data Scientist  90000 - 170000    \n",
       "27                           Data Scientist  70000 - 110000    \n",
       "51            Data Architect/ Data Engineer  65000 - 110000    \n",
       "\n",
       "          salary_split     lower     upper       avg  \n",
       "1            [110000 ]  110000.0       NaN  110000.0  \n",
       "5            [155000 ]  155000.0       NaN  155000.0  \n",
       "6   [90000 ,  170000 ]   90000.0  170000.0  130000.0  \n",
       "27  [70000 ,  110000 ]   70000.0  110000.0   90000.0  \n",
       "51  [65000 ,  110000 ]   65000.0  110000.0   87500.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding an average salary\n",
    "def avg(salaries):\n",
    "    salaries['lower'] = salaries['salary_split'].str[0].astype('float')\n",
    "    salaries['upper'] = salaries['salary_split'].str[1].astype('float')\n",
    "    salaries['avg'] = salaries[['lower','upper']].mean(axis=1)\n",
    "avg(salaries)\n",
    "salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York, NY 10005 (Financial District area)</td>\n",
       "      <td>Barrington James</td>\n",
       "      <td>Real World Evidence Statistical Analyst</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>PMES</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>155000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>indify</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>130000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>WorldCover</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Envisagenics, Inc.</td>\n",
       "      <td>Data Architect/ Data Engineer</td>\n",
       "      <td>87500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        location                   company  \\\n",
       "1   New York, NY 10005 (Financial District area)          Barrington James   \n",
       "5                                   New York, NY                      PMES   \n",
       "6                                   New York, NY                    indify   \n",
       "27                                  New York, NY                WorldCover   \n",
       "51                                  New York, NY        Envisagenics, Inc.   \n",
       "\n",
       "                                  job_title       avg  \n",
       "1   Real World Evidence Statistical Analyst  110000.0  \n",
       "5                         Sr Data Scientist  155000.0  \n",
       "6                            Data Scientist  130000.0  \n",
       "27                           Data Scientist   90000.0  \n",
       "51            Data Architect/ Data Engineer   87500.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping columns so I'm only left with average column\n",
    "clean_sal = salaries.drop(['salary','salary_split', 'lower', 'upper'], axis=1)\n",
    "clean_sal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>avg</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barrington James</td>\n",
       "      <td>Real World Evidence Statistical Analyst</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PMES</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indify</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WorldCover</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Envisagenics, Inc.</td>\n",
       "      <td>Data Architect/ Data Engineer</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company                                job_title  \\\n",
       "1           Barrington James  Real World Evidence Statistical Analyst   \n",
       "5                       PMES                        Sr Data Scientist   \n",
       "6                     indify                           Data Scientist   \n",
       "27                WorldCover                           Data Scientist   \n",
       "51        Envisagenics, Inc.            Data Architect/ Data Engineer   \n",
       "\n",
       "         avg      city state  \n",
       "1   110000.0  New York    NY  \n",
       "5   155000.0  New York    NY  \n",
       "6   130000.0  New York    NY  \n",
       "27   90000.0  New York    NY  \n",
       "51   87500.0  New York    NY  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sal['citystate'] = clean_sal['location'].str.split(',') #splitting the location to separate city and state\n",
    "clean_sal['city'] = clean_sal['citystate'].str[0] #getting cities\n",
    "clean_sal['state'] = clean_sal['citystate'].str[1] #getting states\n",
    "clean_sal['state'] = clean_sal['state'].str[0:3] #getting only 2 letter state codes\n",
    "clean_sal.drop(['location','citystate'], axis=1, inplace=True) #dropping columns so I'm only left with cities/states\n",
    "clean_sal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values \n",
      "company      1\n",
      "job_title    0\n",
      "avg          0\n",
      "city         0\n",
      "state        0\n",
      "dtype: int64\n",
      "dataframe types \n",
      "company       object\n",
      "job_title     object\n",
      "avg          float64\n",
      "city          object\n",
      "state         object\n",
      "dtype: object\n",
      "dataframe shape \n",
      "(402, 5)\n",
      "dataframe describe \n",
      "                 avg\n",
      "count     402.000000\n",
      "mean   111915.820896\n",
      "std     49224.798792\n",
      "min     24000.000000\n",
      "25%     75000.000000\n",
      "50%    106250.000000\n",
      "75%    144887.500000\n",
      "max    275000.000000\n",
      "dataframe length = 402\n",
      "duplicates 0\n",
      "company\n",
      "197\n",
      "job_title\n",
      "317\n",
      "avg\n",
      "148\n",
      "city\n",
      "72\n",
      "state\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "eda(clean_sal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "#saving my clean salary data to a csv\n",
    "clean_sal.to_csv(\"~/Desktop/clean_salary.csv\" , sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       402.000000\n",
       "mean     111915.820896\n",
       "std       49224.798792\n",
       "min       24000.000000\n",
       "25%       75000.000000\n",
       "50%      106250.000000\n",
       "75%      144887.500000\n",
       "max      275000.000000\n",
       "Name: avg, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sal['avg'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106250.0\n"
     ]
    }
   ],
   "source": [
    "#finding the median\n",
    "import numpy as np\n",
    "median = np.median(clean_sal.avg)\n",
    "print median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv('~/Desktop/GA/clean_sal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>avg</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>dumsal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Barrington James</td>\n",
       "      <td>Real World Evidence Statistical Analyst</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>PMES</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>indify</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>WorldCover</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>Envisagenics, Inc.</td>\n",
       "      <td>Data Architect/ Data Engineer</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   company  \\\n",
       "0           1          Barrington James   \n",
       "1           5                      PMES   \n",
       "2           6                    indify   \n",
       "3          27                WorldCover   \n",
       "4          51        Envisagenics, Inc.   \n",
       "\n",
       "                                 job_title       avg      city state  dumsal  \n",
       "0  Real World Evidence Statistical Analyst  110000.0  New York    NY       1  \n",
       "1                        Sr Data Scientist  155000.0  New York    NY       1  \n",
       "2                           Data Scientist  130000.0  New York    NY       1  \n",
       "3                           Data Scientist   90000.0  New York    NY       0  \n",
       "4            Data Architect/ Data Engineer   87500.0  New York    NY       0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['dumsal'] = (c[\"avg\"] >= c[\"avg\"].median()).astype(int)\n",
    "#http://stackoverflow.com/questions/36637011/how-can-i-create-a-dummy-variable-in-python-with-a-condition-below-or-above-medi\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer()\n",
    "X = c.job_title\n",
    "y = c.dumsal\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english').fit(X_train)\n",
    "df_train = pd.DataFrame(cvec.transform(X_train).todense(),\n",
    "             columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269, 314)\n",
      "(269,)\n",
      "(133, 314)\n",
      "(133,)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame(cvec.transform(X_test).todense(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "print df_train.shape\n",
    "print y_train.shape\n",
    "print df_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80451127819548873"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(df_train, y_train)\n",
    "lr.score(df_test, y_test)\n",
    "#this is my title score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.47826087  0.39130435  0.40909091  0.40909091  0.36363636  0.38095238]\n",
      "Cross-Predicted Accuracy: 0.406015037594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(lr, df_test, y_test, cv=6)\n",
    "print \"Cross-validated scores:\", scores\n",
    "# Make cross validated predictions\n",
    "predictions = cross_val_predict(lr, df_test, y_test, cv=6)\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print \"Cross-Predicted Accuracy:\", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Score:\t0.807 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "RF = rf.fit(df_train,y_train)\n",
    "s = cross_val_score(rf, df_train, y_train, n_jobs=-1)\n",
    "print \"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Random Forrest\", s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.104554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>0.053279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>0.052167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst</th>\n",
       "      <td>0.037202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>0.031317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <td>0.026832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.022557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior</th>\n",
       "      <td>0.021921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>0.021450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analytics</th>\n",
       "      <td>0.018560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           importance\n",
       "data         0.104554\n",
       "scientist    0.053279\n",
       "learning     0.052167\n",
       "analyst      0.037202\n",
       "engineer     0.031317\n",
       "machine      0.026832\n",
       "research     0.022557\n",
       "senior       0.021921\n",
       "science      0.021450\n",
       "analytics    0.018560"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_features = pd.DataFrame(RF.feature_importances_,\n",
    "                                   index = df_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "rf_features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in my dataframe to represent interesting features of a job title. Then I built a new Random Forest with these features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>avg</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>dumsal</th>\n",
       "      <th>visualization</th>\n",
       "      <th>manager</th>\n",
       "      <th>scientist</th>\n",
       "      <th>engineer</th>\n",
       "      <th>senior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Barrington James</td>\n",
       "      <td>Real World Evidence Statistical Analyst</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>PMES</td>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>indify</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>WorldCover</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>Envisagenics, Inc.</td>\n",
       "      <td>Data Architect/ Data Engineer</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   company  \\\n",
       "0           1          Barrington James   \n",
       "1           5                      PMES   \n",
       "2           6                    indify   \n",
       "3          27                WorldCover   \n",
       "4          51        Envisagenics, Inc.   \n",
       "\n",
       "                                 job_title       avg      city state  dumsal  \\\n",
       "0  Real World Evidence Statistical Analyst  110000.0  New York    NY       1   \n",
       "1                        Sr Data Scientist  155000.0  New York    NY       1   \n",
       "2                           Data Scientist  130000.0  New York    NY       1   \n",
       "3                           Data Scientist   90000.0  New York    NY       0   \n",
       "4            Data Architect/ Data Engineer   87500.0  New York    NY       0   \n",
       "\n",
       "   visualization  manager  scientist  engineer  senior  \n",
       "0              0        0          0         0       0  \n",
       "1              0        0          1         0       1  \n",
       "2              0        0          1         0       0  \n",
       "3              0        0          1         0       0  \n",
       "4              0        0          0         1       0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manager, visualization, scientist, engineer, analyst, senior\n",
    "c['visualization'] = map(int, c['job_title'].str.lower().str.contains('vis'))\n",
    "c['manager'] = map(int, c['job_title'].str.lower().str.contains('manager')|\n",
    "                  c['job_title'].str.lower().str.contains('mngr')|\n",
    "                  c['job_title'].str.lower().str.contains('mgr'))\n",
    "c['scientist'] = map(int, c['job_title'].str.lower().str.contains('scien'))\n",
    "c['engineer'] = map(int, c['job_title'].str.lower().str.contains('eng'))\n",
    "c['senior'] = map(int, c['job_title'].str.lower().str.contains('sr')|\n",
    "                  c['job_title'].str.lower().str.contains('snr')|\n",
    "                  c['job_title'].str.lower().str.contains('senior'))\n",
    "#making dummies for the words at the top of this cell\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76691729323308266"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#completing a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = c[['manager', 'visualization', 'scientist', 'engineer', 'senior']]\n",
    "y = c.dumsal\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)\n",
    "#this is my concatonated score since it's worse I'm only going to use  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Score:\t0.729 ± 0.019\n"
     ]
    }
   ],
   "source": [
    "#and a random forest classifier\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "s = cross_val_score(rf, X, y, n_jobs=-1)\n",
    "print \"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Random Forrest\", s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [ 0.58823529  0.77941176  0.79411765  0.74242424  0.68181818  0.75757576]\n",
      "Cross-Predicted Accuracy: 0.713930348259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "# Perform 6-fold cross validation\n",
    "scores = cross_val_score(rf, X, y, cv=6)\n",
    "print \"Cross-validated scores:\", scores\n",
    "# Make cross validated predictions\n",
    "predictions = cross_val_predict(rf, X, y, cv=6)\n",
    "accuracy = metrics.accuracy_score(y, predictions)\n",
    "print \"Cross-Predicted Accuracy:\", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [],
   "source": [
    "#sending my final to a csv\n",
    "c.to_csv(\"~/Desktop/c.csv\" , sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
